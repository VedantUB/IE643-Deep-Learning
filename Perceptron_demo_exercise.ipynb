{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VedantUB/IE643-Deep-Learning/blob/main/Perceptron_demo_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a7ibL5sXbId"
      },
      "outputs": [],
      "source": [
        "#import the required packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "np.random.seed(1000) #seed the random number generator for repeatability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uryc-fZZXbIi"
      },
      "source": [
        "Python modules required for plotting the data points and the hyperplane"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSBTAPM9XbIk"
      },
      "outputs": [],
      "source": [
        "def Plot_datapoints(p1,q1,p2,q2):\n",
        "    plt.scatter(p1,q1)\n",
        "    plt.scatter(p2,q2)\n",
        "    plt.grid(b = True, which = 'both')\n",
        "    plt.xlabel(\"x coordinate\")\n",
        "    plt.ylabel(\"y coordinate\")\n",
        "    plt.title(\"Data\")\n",
        "    plt.show()\n",
        "\n",
        "def Plot_Classifier_with_bias(data, w):\n",
        "    x_points=[]\n",
        "    for i in range(len(data)):\n",
        "        x_points.append(data[i][0][0])\n",
        "    maximum = max(x_points)\n",
        "    minimum = min(x_points)\n",
        "    points = []\n",
        "    x_points = np.linspace(minimum,maximum,1000)\n",
        "    for i in range(len(x_points)):\n",
        "        points.append((-w[0]*x_points[i]-w[2])/w[1])\n",
        "\n",
        "    plt.plot(x_points,points,color='black')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke7MyrjUXbIm"
      },
      "source": [
        "Python module used for perceptron's prediction rule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXSG78uXXbIn"
      },
      "outputs": [],
      "source": [
        "def prediction(w, x):\n",
        "    #Write code to return a prediction of +1 or -1 according to the perceptron prediction rule\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NagrvF0OXbIp"
      },
      "source": [
        "Python module used for updating the weights of Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxpDkM-wXbIr"
      },
      "outputs": [],
      "source": [
        "def update_weights(weight, y_label, x_feature, y_pred, misclass):\n",
        "    #write code to update weight and add 1 to misclass if the perceptron misclassifies x_feature\n",
        "\n",
        "    return weight , misclass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBPAqMBHXbIu"
      },
      "source": [
        "Python module used for Perceptron training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DilGMjQVXbIv"
      },
      "outputs": [],
      "source": [
        "def perceptron_training(data):\n",
        "    w =np.random.randn(3)  # randomly generating w\n",
        "    flag=0\n",
        "    mistakes = 0\n",
        "    epochs=0\n",
        "\n",
        "    while flag==0 and epochs<50:   # until mistakes are not zero or number of epochs reach 50\n",
        "        mistakes=0\n",
        "\n",
        "        #we visualize the hyperplane each time to check for progress\n",
        "        Plot_Classifier_with_bias(data, w)\n",
        "\n",
        "        Plot_datapoints(x1,y1,x2,y2)\n",
        "\n",
        "        for i in range(len(data)):\n",
        "            x = data[i][0]\n",
        "            x = np.concatenate((x,np.ones(1)),axis = 0)\n",
        "            y_hat = prediction(w, x)\n",
        "\n",
        "            y = data[i][1]\n",
        "\n",
        "            w , mistakes= update_weights(w, y, x, y_hat, mistakes)\n",
        "\n",
        "        epochs=epochs+1\n",
        "        if mistakes==0:\n",
        "            flag=1\n",
        "    return w, mistakes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1coZrG_eXbIx"
      },
      "source": [
        "Data Creation and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugA_W5YGXbIx"
      },
      "outputs": [],
      "source": [
        "# Data creation, plot the data, and train perceptron\n",
        "\n",
        "#Use your homework to create 1000 points from a two-dimensionsal normal distribution with mean [6 ,6] and variance [[1, 0], [0,1]]\n",
        "#Assign the points to data1\n",
        "#data1 = ???\n",
        "\n",
        "\n",
        "#Use your homework to create 1000 points from a two-dimensionsal normal distribution with mean [0 ,0] and variance [[1, 0], [0,1]]\n",
        "#Assign the points to data1\n",
        "#data2 = ???\n",
        "\n",
        "#We will the data points by plotting\n",
        "x1 = []\n",
        "y1 = []\n",
        "x2 = []\n",
        "y2 = []\n",
        "for i in range(len(data1)):\n",
        "    x1.append(data1[i][0])\n",
        "    y1.append(data1[i][1])\n",
        "    x2.append(data2[i][0])\n",
        "    y2.append(data2[i][1])\n",
        "\n",
        "Plot_datapoints(x1,y1,x2,y2) #This function is available below\n",
        "#Note that the purpose of x1,y1,x2,y2 is required only for plotting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lKPMArZXbIy"
      },
      "source": [
        "Label the data points, shuffle them and train perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nY0CvfhXbIz"
      },
      "outputs": [],
      "source": [
        "#Let us put points in data1 and data2 in a single array called data and attach labels to them\n",
        "data = []\n",
        "for i in range(len(data1)):\n",
        "    data.append((data1[i],1))\n",
        "\n",
        "for i in range(len(data2)):\n",
        "    data.append((data2[i],-1))\n",
        "\n",
        "#We will shuffle the data (Think why should we do this?)\n",
        "random.shuffle(data)\n",
        "\n",
        "#Train a perceptron on data, get the optimal w as w_star and the number of mistakes\n",
        "w_star,mistakes=perceptron_training(data)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cetz06dsXbIz"
      },
      "source": [
        "Print the number of mistakes and the optimal weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDqBKYkwXbI0"
      },
      "outputs": [],
      "source": [
        "#print the number of mistakes\n",
        "print(mistakes)\n",
        "\n",
        "#print the optimal w\n",
        "print(w_star)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLRpc3SOXbI0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}